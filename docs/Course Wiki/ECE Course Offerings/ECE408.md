# ECE408

ECE408 (Applied Parllel Programming) is a 4-credit-hour senior level course that satisifes the Advanced Computing elective requirement for Computer Engineering majors.

## Content Covered:
- CUDA C Programming
- NVIDIA Nsight Compute / Nsys profile tools
- GPU vs CPU Architecture
- Memory Bandwith Optimizations
- Reductions, Convolution
- Matrix Multiplication Techniques
- Sparse Matrix Formats
- GPU Streaming
- Alternatives to CUDA
- Neural Networks
- Atomics
- Tiling

## Prerequisites 
- [ECE220](ECE220.md)

ECE 220 is listed as a prerequisite, as most of this course is taught in C and requires a good understanding of pointers and memory management. For students not confident in their C skills, it may be wise to wait until taking ECE 391 or CS 225 in order to improve their programming skills first.

## When To Take It
The class does not require a very high workload, so don't worry much about taking this with other hard ECE classes. Taking this class before 411 may be a good introduction between the GPUs and CPUs.

In general, 408 is a valuable class to take as someone wanting to work with low-level software or computer architecture. Parallel Programming and the differences between GPUs and CPUs are important topics to understand for any Computer Engineering student. For those interested in Nvidia internships, knowing CUDA will definitely give you an edge, but the concepts taught in the class extend to all companies and all GPU programming.


## Course Structure
### Lecture
Lecture is traditionaly twice a week in 1:20 
### MPs
### 
Applied Parallel Programming has been taught by Professor Wen-Mei Hwu in the past, who designed the class material and remains the course director. It is currently being taught by Professor Sanjay Patel and Professor Volodymyr Kindratenko in Fall 2020. There is usually 1 TA who assigns and grades the MPs.

Prerequisites:
ECE 220 (previously ECE 190) is listed as a prerequisite, as most of this course is taught in C. However, it is recommended that students acquire some more hands-on experience coding in C or C++ than ECE 220, as they will get more out of the course. Courses such as CS 225 and/or ECE 391 would provide a particularly strong background for this course, though it is not necessary.

When to Take It:
The course is typically offered during both the Fall and Spring semesters. Most students take this technical elective during their Junior or Senior year.

Class Content:
The primary framework used in this class is CUDA, a C-like language maintained by NVIDIA that supports programming on GPUs and GPU clusters.

Much of the class is spent comparing and contrasting serial vs. parallel implementations of various widely-used computing algorithms. Each algorithm typically introduces new CUDA features, which students utilize in the MPs.

Some of the main topics covered in this course include:

CUDA programming language

Parallel software design

Performance enhancements

Scalability

Processor architecture features and constraints

Applications of parallel programming

State of the parallel programming industry

This course has also included a few guest lectures in past semesters, from people who use parallel programming in their work or research. Fall 2018 the guest lecturers included representatives from Jaunt XR. In Fall 2020, the guest lecturers included representatives from Intel, NVIDIA and AMD.

Work:
For 4 credit hours, this class is not terribly work intensive during the semester. However, it is more intensive than it used to be in previous years. Students will need to put in extra time or focus during lectures to understand the underlying CUDA architecture and algorithm structure. The lecture material prepares students very well for the assignments, with important portions of the project are typically explained and analyzed thoroughly in lecture before the due date. Having a strong understanding of the problem and the parallel solution helps incredibly in test and MP performance.

Lectures are typically 75 minutes, 2 days a week, and there are no discussion or lab sections. The assignments consist of 6-7 MPs that are all written in CUDA and executed on a GPU cluster (WebGPU). As of Fall 2020, each MP has a set of questions for each problem, worth 10% of the MP. The questions ask the student to comment on the performance of their own code as well as to compare the characteristics of differing algorithms to solve the same problem.

This course also includes a final project component where students work in teams of 3-4 to apply the concepts they have learned throughout the semester. Teams are set to participate in a class-wide “competition” project. The competition is typically a standard problem that can be parallelized in a wide variety of manners, with students competing to design the most efficient parallel implementation. For Fall 2018 and Fall 2020, the competition was to design an optimized neural-network convolution layer forward pass. The final project is primarily graded on the checkpoint reports and optimizations used over the ~2 months given for the project. The ranking of speed accounts for 10% of the final project grade.

As of Fall 2018, there are two exams throughout the semester, which are 3-hour timed paper exams.

The exams have multiple choice, short answer, and code problems where you fill in the missing parameters. The content of the exams covers algorithms used in MPs as well as unused options brought up in lecture. Another significant topic is the effect of certain parameters and algorithms on the performance of the program.

During Fall 2020, the two exams are 1.5 hours long. They are very fast paced and difficult to prepare for.

During Spring 2021 with Professor Kindratenko, the final project became a solo project, and the ranking of speed was dropped from being a factor in grades.

As of Spring 2023, the two exams are 1.5 hours long, completely open note, and entirely on canvas, with optional zoom help while you are taking the exam.



Grade breakdown (for Spring 2023):

Exam 1: 20%

Exam 2: 20%

Labs (Machine Problems): 35% (5% each)

Correctness (number of datasets passed): 90%

Report/questions: 10%

Lab with lowest score will be dropped.

Project: 25%

Milestone 1: 20%

Correctness (15%)

Report (5%)
Milestone 2: 30%

Correctness (20%)

Report (10%)

Milestone 3: 50%

Overall Performance (10%)

Correctness (2% for each optimization point, 20% maximum)

Report (2% for each optimizatino point, 20% maximum)

Extra Credit: (up to +5% maximum, +2.5% per additional optimization point)

Life After:
If you really enjoyed this course, check out CS 420 (ECE 493) - Parallel Progrmg: Sci & Engrg.

If you are interested in working on the CUDA language itself or contributing to open parallelism platforms such as OpenMP, consider applying for internships at companies such as NVIDIA, AMD, and Intel.

If you are open to applying CUDA or parallel computing in industry, there are a wide variety of opportunities available.

In addition, expertise in parallel programming is highly valued in the academic community, particularly in research areas that deal with large amounts of data such as computational genomics and biomedical imaging. There are many opportunities for undergraduate and graduate students to get involved with research on campus if they are competent in parallel software design.
